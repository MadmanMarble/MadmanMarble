{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO8ThIDnDeRe51pD+e/PnZv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MadmanMarble/MadmanMarble/blob/main/Untitled34.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8zkhfI0TixX",
        "outputId": "97b12cff-1cd4-4cf7-8b1d-2ac5ebdad06a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio scikit-image tensorflow keras gdown\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_yfvgB7VA5L",
        "outputId": "be57b852-0a28-4dfd-95d9-8eb3e19694d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.9-cp310-cp310-manylinux2014_x86_64.whl (20.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.2.2)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.25.2)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.9 snuggs-1.4.7\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import gdown\n",
        "import zipfile\n",
        "import cv2\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shutil\n",
        "import rasterio\n",
        "import rasterio.plot\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from keras.utils import Sequence, to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.transform import resize\n",
        "from skimage.util import random_noise\n",
        "from scipy import ndimage\n",
        "from scipy.ndimage import label as nd_label\n",
        "from scipy.ndimage import generic_filter\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Additional code can be added here if needed"
      ],
      "metadata": {
        "id": "CeNbsirhU_KR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train test split"
      ],
      "metadata": {
        "id": "2p0o5HxEcoI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths_2018 = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/*.tif\")\n",
        "image_paths_2019 = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2019/*.tif\")\n",
        "image_paths_2020 = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2020/*.tif\")\n",
        "dem_path = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/dem/*.tif\")\n",
        "nwi_ccap_path = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/*.tif\")\n",
        "label_paths = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/ccap_filled/*.tif\")"
      ],
      "metadata": {
        "id": "f_4Fqb03fRBA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "end"
      ],
      "metadata": {
        "id": "8PYvjX7rcrfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, image_files, label_files, img_height, img_width, batch_size, num_classes):\n",
        "        self.image_files = image_files\n",
        "        self.label_files = label_files\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        # self.noise = noise\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_files) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_batch_files = self.image_files[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "        label_batch_files = self.label_files[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "\n",
        "        batch_images, batch_labels = self.load_images_and_labels(image_batch_files,label_batch_files)\n",
        "        return batch_images, batch_labels\n",
        "\n",
        "    def load_and_reshape_image(self, image_path):\n",
        "        with rasterio.open(image_path) as src:\n",
        "            image = src.read()\n",
        "            image = image.transpose((1, 2, 0))\n",
        "            if image.shape[0] != self.img_height or image.shape[1] != self.img_width:\n",
        "                image = cv2.resize(image, (self.img_width, self.img_height), interpolation=cv2.INTER_NEAREST)\n",
        "            if len(image.shape) == 3 and image.shape[2] == 1:\n",
        "                image = np.squeeze(image, axis=2)\n",
        "\n",
        "            return image\n",
        "\n",
        "    def load_images_and_labels(self, image_files, label_files):\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for image_file in image_files:\n",
        "            image = self.load_and_reshape_image(image_file)\n",
        "            # image[image <= -3e+38] = np.nan\n",
        "\n",
        "            # # # Replace NaN values with the mean of the non-NaN pixels\n",
        "            # if np.any(np.isnan(image)):\n",
        "            #     nan_mask = np.isnan(image)\n",
        "            #     image[nan_mask] = np.nanmean(image)\n",
        "\n",
        "            # # # Replace Inf values with the mean of the non-Inf pixels\n",
        "            # if np.any(np.isinf(image)):\n",
        "            #     inf_mask = np.isinf(image)\n",
        "            #     image[inf_mask] = np.nanmean(image)\n",
        "\n",
        "            # # Convert to float\n",
        "            # image = image.astype(np.float32)\n",
        "\n",
        "            # # Z-score normalization\n",
        "            # mean = np.mean(image, axis=(0, 1), keepdims=True)\n",
        "            # std = np.std(image, axis=(0, 1), keepdims=True)\n",
        "            # # mean[mean < 0]\n",
        "            # std[std < 0] = 0\n",
        "\n",
        "            # # Normalize with epsilon to prevent divide by zero\n",
        "            # epsilon = 1e-7\n",
        "\n",
        "            # image = (image - mean) / (std + epsilon)\n",
        "\n",
        "            images.append(image)\n",
        "\n",
        "        for label_file in label_files:\n",
        "            # label_file = image_file.replace(\"planet\", \"ccap_filled\").replace('images_2018','ccap_filled')\n",
        "            label = self.load_and_reshape_image(label_file)\n",
        "            # label[label <= -3e+38] = np.nan\n",
        "\n",
        "            # # # Replace NaN values with the mean of the non-NaN pixels\n",
        "            # if np.any(np.isnan(label)):\n",
        "            #     nan_mask = np.isnan(label)\n",
        "            #     label[nan_mask] = 12\n",
        "\n",
        "            # # # Replace Inf values with the mean of the non-Inf pixels\n",
        "            # if np.any(np.isinf(label)):\n",
        "            #     inf_mask = np.isinf(label)\n",
        "            #     label[inf_mask] = 12\n",
        "\n",
        "            label -= 1\n",
        "            label = label.astype(np.int8)\n",
        "            label = to_categorical(label, num_classes=self.num_classes)\n",
        "            labels.append(label)\n",
        "\n",
        "        return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "ZGapBsD-T4zX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_paths = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm4/images_2018/*.tif\")\n",
        "train_label_paths = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm4/ccap_filled/*.tif\")\n",
        "\n",
        "# val_image_paths = glob.glob(f\"{base_dir}/validation/image/*.tif\")\n",
        "# val_label_paths = glob.glob(f\"{base_dir}/validation/label/*.tif\")"
      ],
      "metadata": {
        "id": "pI1Wn2EDWfzt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_label_paths[0])\n",
        "train_image_paths[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "5-3jmoCAWx15",
        "outputId": "f0227e45-066b-47ae-c18a-a5204b0576b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm4/ccap_filled/3_ccap_filled.tif\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm4/images_2018/1814_planet.tif'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm4/images_2018"
      ],
      "metadata": {
        "id": "n7VYRQYfV-m6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_gen_test = DataGenerator(sum_df['Images_path'][0:5], sum_df['Labels_path'][0:5], 512, 512, 2, 22)\n",
        "# Create the data generator\n",
        "training_data_generator = DataGenerator(train_image_paths, train_label_paths, 128, 128, 4, 12)\n",
        "# validation_data_generator = DataGenerator(sum_df['Images_path'][sum_df['random_split']==1], sum_df['Labels_path'][sum_df['random_split']==1], 512, 512, 4, 25)\n"
      ],
      "metadata": {
        "id": "yCwfJD8nViEi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm4/ccap_filled/1004_ccap_filled.tif"
      ],
      "metadata": {
        "id": "Xr38sNZ5ZGun"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_images, batch_labels = training_data_generator.__getitem__(0)"
      ],
      "metadata": {
        "id": "oY0rx_yqX3hX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_model(img_size,num_bands, num_classes):\n",
        "#     inputs = keras.Input(shape=(img_size[0], img_size[1], num_bands))  # Change the number of channels to 4\n",
        "\n",
        "#     # Entry block\n",
        "#     x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "#     x = layers.BatchNormalization()(x)\n",
        "#     x = layers.Activation(\"LeakyReLU\")(x)\n",
        "\n",
        "#     previous_block_activation = x  # Set aside residual\n",
        "\n",
        "#     # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "#     for filters in [64, 128, 256]:\n",
        "#         x = layers.Activation(\"LeakyReLU\")(x)\n",
        "#         x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         x = layers.Activation(\"LeakyReLU\")(x)\n",
        "#         x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "#         # Project residual\n",
        "#         residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "#             previous_block_activation\n",
        "#         )\n",
        "#         x = layers.add([x, residual])  # Add back residual\n",
        "#         previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "#     for filters in [256, 128, 64, 32]:\n",
        "#         x = layers.Activation(\"LeakyReLU\")(x)\n",
        "#         x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         x = layers.Activation(\"LeakyReLU\")(x)\n",
        "#         x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "#         residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "#         residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "#         x = layers.add([x, residual])  # Add back residual\n",
        "#         previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "#     # Add a per-pixel classification layer\n",
        "#     outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "#     # Define the model\n",
        "#     model = keras.Model(inputs, outputs)\n",
        "#     model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # updated to sparse categorical cross-entropy loss\n",
        "#     return model"
      ],
      "metadata": {
        "id": "9HXLq2bqarAU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "# from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "\n",
        "# from tensorflow.keras.layers import BatchNormalization\n",
        "# from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "# from tensorflow.python.keras.layers import BatchNormalization\n",
        "\n",
        "# U-Net model for image segmentation.\n",
        "# Encoder and decoder conncted by a center block.\n",
        "# Encoder downsamples the input image while capturing its features.\n",
        "# Decoder upsamples the encoded image to generate a segmentation map.\n",
        "\n",
        "def conv_block(input_tensor, num_filters):\n",
        "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
        "\tencoder = layers.BatchNormalization()(encoder)\n",
        "\tencoder = layers.Activation('LeakyReLU')(encoder) # from relu to LeakyReLU\n",
        "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
        "\tencoder = layers.BatchNormalization()(encoder)\n",
        "\tencoder = layers.Activation('LeakyReLU')(encoder) # from relu to LeakyReLU\n",
        "\treturn encoder\n",
        "\n",
        "def encoder_block(input_tensor, num_filters):\n",
        "\tencoder = conv_block(input_tensor, num_filters)\n",
        "\tencoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
        "\treturn encoder_pool, encoder\n",
        "\n",
        "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
        "\tdecoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
        "\tdecoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('LeakyReLU')(decoder) # from relu to LeakyReLU\n",
        "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('LeakyReLU')(decoder) # from relu to LeakyReLU\n",
        "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('LeakyReLU')(decoder) # from relu to LeakyReLU\n",
        "\treturn decoder\n",
        "\n",
        "def get_model():\n",
        "\tinputs = layers.Input(shape=[KERNEL_SIZE, KERNEL_SIZE, len(BANDS)]) # 256\n",
        "\tencoder0_pool, encoder0 = encoder_block(inputs, 32) # 128\n",
        "\tencoder1_pool, encoder1 = encoder_block(encoder0_pool, 64) # 64\n",
        "\tencoder2_pool, encoder2 = encoder_block(encoder1_pool, 128) # 32\n",
        "\tencoder3_pool, encoder3 = encoder_block(encoder2_pool, 256) # 16\n",
        "\tencoder4_pool, encoder4 = encoder_block(encoder3_pool, 512) # 8\n",
        "\tcenter = conv_block(encoder4_pool, 1024) # center\n",
        "\tdecoder4 = decoder_block(center, encoder4, 512) # 16\n",
        "\tdecoder3 = decoder_block(decoder4, encoder3, 256) # 32\n",
        "\tdecoder2 = decoder_block(decoder3, encoder2, 128) # 64\n",
        "\tdecoder1 = decoder_block(decoder2, encoder1, 64) # 128\n",
        "\tdecoder0 = decoder_block(decoder1, encoder0, 32) # 256\n",
        "\toutputs = layers.Conv2D(CLASSES, (1, 1), activation='softmax')(decoder0) # kept because this is a multiclass classification\n",
        "\n",
        "\tmodel = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "\tmodel.compile(\n",
        "\t\toptimizer=optimizers.get(OPTIMIZER),\n",
        "\t\tloss=losses.get(LOSS),\n",
        "\t\tmetrics=[metrics.get(metric) for metric in METRICS])\n",
        "\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "WOU26Rp1chre"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KERNEL_SIZE = 128\n",
        "CLASSES = 12\n",
        "BANDS = range(4)\n",
        "KERNEL_SHAPE = [128, 128]\n",
        "OPTIMIZER = 'adam'\n",
        "LOSS = 'categorical_crossentropy'\n",
        "METRICS = ['categorical_accuracy']"
      ],
      "metadata": {
        "id": "7MYIse8Lc9qy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import TenserFlow classes and functions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "NzskjnjKdRID"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = create_model([128,128],4,11)\n",
        "model = get_model()"
      ],
      "metadata": {
        "id": "8PJpkjavbr5u"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20VM6nuhg_si",
        "outputId": "0079522a-6994-42dd-cb81-ff2be31b2c40"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 128, 128, 4)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 128, 128, 32)         1184      ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 128, 128, 32)         128       ['conv2d_23[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_27 (Activation)  (None, 128, 128, 32)         0         ['batch_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 128, 128, 32)         9248      ['activation_27[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 128, 128, 32)         128       ['conv2d_24[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_28 (Activation)  (None, 128, 128, 32)         0         ['batch_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 64, 64, 32)           0         ['activation_28[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 64, 64, 64)           18496     ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_29 (Ba  (None, 64, 64, 64)           256       ['conv2d_25[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_29 (Activation)  (None, 64, 64, 64)           0         ['batch_normalization_29[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 64, 64, 64)           36928     ['activation_29[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_30 (Ba  (None, 64, 64, 64)           256       ['conv2d_26[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_30 (Activation)  (None, 64, 64, 64)           0         ['batch_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPoolin  (None, 32, 32, 64)           0         ['activation_30[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 32, 32, 128)          73856     ['max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_31 (Ba  (None, 32, 32, 128)          512       ['conv2d_27[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_31 (Activation)  (None, 32, 32, 128)          0         ['batch_normalization_31[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 32, 32, 128)          147584    ['activation_31[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_32 (Ba  (None, 32, 32, 128)          512       ['conv2d_28[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_32 (Activation)  (None, 32, 32, 128)          0         ['batch_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPoolin  (None, 16, 16, 128)          0         ['activation_32[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 16, 16, 256)          295168    ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_33 (Ba  (None, 16, 16, 256)          1024      ['conv2d_29[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_33 (Activation)  (None, 16, 16, 256)          0         ['batch_normalization_33[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 16, 16, 256)          590080    ['activation_33[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 16, 16, 256)          1024      ['conv2d_30[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_34 (Activation)  (None, 16, 16, 256)          0         ['batch_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPoolin  (None, 8, 8, 256)            0         ['activation_34[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 8, 8, 512)            1180160   ['max_pooling2d_8[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_35 (Ba  (None, 8, 8, 512)            2048      ['conv2d_31[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_35 (Activation)  (None, 8, 8, 512)            0         ['batch_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 8, 8, 512)            2359808   ['activation_35[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_36 (Ba  (None, 8, 8, 512)            2048      ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_36 (Activation)  (None, 8, 8, 512)            0         ['batch_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPoolin  (None, 4, 4, 512)            0         ['activation_36[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 4, 4, 1024)           4719616   ['max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_37 (Ba  (None, 4, 4, 1024)           4096      ['conv2d_33[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_37 (Activation)  (None, 4, 4, 1024)           0         ['batch_normalization_37[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 4, 4, 1024)           9438208   ['activation_37[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_38 (Ba  (None, 4, 4, 1024)           4096      ['conv2d_34[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_38 (Activation)  (None, 4, 4, 1024)           0         ['batch_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2D  (None, 8, 8, 512)            2097664   ['activation_38[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 8, 8, 1024)           0         ['activation_36[0][0]',       \n",
            " )                                                                   'conv2d_transpose_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (Ba  (None, 8, 8, 1024)           4096      ['concatenate_5[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_39 (Activation)  (None, 8, 8, 1024)           0         ['batch_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 8, 8, 512)            4719104   ['activation_39[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_40 (Ba  (None, 8, 8, 512)            2048      ['conv2d_35[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_40 (Activation)  (None, 8, 8, 512)            0         ['batch_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 8, 8, 512)            2359808   ['activation_40[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_41 (Ba  (None, 8, 8, 512)            2048      ['conv2d_36[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_41 (Activation)  (None, 8, 8, 512)            0         ['batch_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2D  (None, 16, 16, 256)          524544    ['activation_41[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate  (None, 16, 16, 512)          0         ['activation_34[0][0]',       \n",
            " )                                                                   'conv2d_transpose_6[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (Ba  (None, 16, 16, 512)          2048      ['concatenate_6[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_42 (Activation)  (None, 16, 16, 512)          0         ['batch_normalization_42[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 16, 16, 256)          1179904   ['activation_42[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_43 (Ba  (None, 16, 16, 256)          1024      ['conv2d_37[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_43 (Activation)  (None, 16, 16, 256)          0         ['batch_normalization_43[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)          (None, 16, 16, 256)          590080    ['activation_43[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_44 (Ba  (None, 16, 16, 256)          1024      ['conv2d_38[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_44 (Activation)  (None, 16, 16, 256)          0         ['batch_normalization_44[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2D  (None, 32, 32, 128)          131200    ['activation_44[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate  (None, 32, 32, 256)          0         ['activation_32[0][0]',       \n",
            " )                                                                   'conv2d_transpose_7[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (Ba  (None, 32, 32, 256)          1024      ['concatenate_7[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_45 (Activation)  (None, 32, 32, 256)          0         ['batch_normalization_45[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)          (None, 32, 32, 128)          295040    ['activation_45[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_46 (Ba  (None, 32, 32, 128)          512       ['conv2d_39[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_46 (Activation)  (None, 32, 32, 128)          0         ['batch_normalization_46[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)          (None, 32, 32, 128)          147584    ['activation_46[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_47 (Ba  (None, 32, 32, 128)          512       ['conv2d_40[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_47 (Activation)  (None, 32, 32, 128)          0         ['batch_normalization_47[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_8 (Conv2D  (None, 64, 64, 64)           32832     ['activation_47[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate  (None, 64, 64, 128)          0         ['activation_30[0][0]',       \n",
            " )                                                                   'conv2d_transpose_8[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_48 (Ba  (None, 64, 64, 128)          512       ['concatenate_8[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_48 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_48[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)          (None, 64, 64, 64)           73792     ['activation_48[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_49 (Ba  (None, 64, 64, 64)           256       ['conv2d_41[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_49 (Activation)  (None, 64, 64, 64)           0         ['batch_normalization_49[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)          (None, 64, 64, 64)           36928     ['activation_49[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_50 (Ba  (None, 64, 64, 64)           256       ['conv2d_42[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_50 (Activation)  (None, 64, 64, 64)           0         ['batch_normalization_50[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_9 (Conv2D  (None, 128, 128, 32)         8224      ['activation_50[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate  (None, 128, 128, 64)         0         ['activation_28[0][0]',       \n",
            " )                                                                   'conv2d_transpose_9[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_51 (Ba  (None, 128, 128, 64)         256       ['concatenate_9[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_51 (Activation)  (None, 128, 128, 64)         0         ['batch_normalization_51[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)          (None, 128, 128, 32)         18464     ['activation_51[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_52 (Ba  (None, 128, 128, 32)         128       ['conv2d_43[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_52 (Activation)  (None, 128, 128, 32)         0         ['batch_normalization_52[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)          (None, 128, 128, 32)         9248      ['activation_52[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_53 (Ba  (None, 128, 128, 32)         128       ['conv2d_44[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_53 (Activation)  (None, 128, 128, 32)         0         ['batch_normalization_53[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)          (None, 128, 128, 12)         396       ['activation_53[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31127148 (118.74 MB)\n",
            "Trainable params: 31111148 (118.68 MB)\n",
            "Non-trainable params: 16000 (62.50 KB)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy','categorical_accuracy'])\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"landcover_segmentation.h5\", save_best_only=True)\n",
        "]\n",
        "\n",
        "model.fit(training_data_generator, epochs=10, callbacks=callbacks,shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTy_jam1bOnZ",
        "outputId": "7f0f3a5e-0343-46a9-8c8d-4f548a2937ac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "658/658 [==============================] - ETA: 0s - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r658/658 [==============================] - 914s 1s/step - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282\n",
            "Epoch 2/10\n",
            "658/658 [==============================] - ETA: 0s - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r658/658 [==============================] - 671s 1s/step - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282\n",
            "Epoch 3/10\n",
            "658/658 [==============================] - ETA: 0s - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r658/658 [==============================] - 624s 948ms/step - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282\n",
            "Epoch 4/10\n",
            "658/658 [==============================] - ETA: 0s - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r658/658 [==============================] - 685s 1s/step - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282\n",
            "Epoch 5/10\n",
            "658/658 [==============================] - ETA: 0s - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r658/658 [==============================] - 661s 1s/step - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282\n",
            "Epoch 6/10\n",
            "658/658 [==============================] - ETA: 0s - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r658/658 [==============================] - 607s 923ms/step - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282\n",
            "Epoch 7/10\n",
            "658/658 [==============================] - ETA: 0s - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r658/658 [==============================] - 581s 884ms/step - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282\n",
            "Epoch 8/10\n",
            "658/658 [==============================] - ETA: 0s - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r658/658 [==============================] - 575s 874ms/step - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282\n",
            "Epoch 9/10\n",
            "658/658 [==============================] - ETA: 0s - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r658/658 [==============================] - 595s 900ms/step - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282\n",
            "Epoch 10/10\n",
            "658/658 [==============================] - ETA: 0s - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r658/658 [==============================] - 540s 820ms/step - loss: nan - accuracy: 0.1282 - categorical_accuracy: 0.1282\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c759026e170>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}