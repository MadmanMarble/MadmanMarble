{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPjPopYneXsZ6XxVgb70pCj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MadmanMarble/MadmanMarble/blob/main/Untitled34.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8zkhfI0TixX",
        "outputId": "a0ca0b85-5862-4b8f-9df9-0b78b41a0f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio scikit-image tensorflow keras gdown\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_yfvgB7VA5L",
        "outputId": "c4766980-fe59-4881-b53a-ff8f33c2eb12"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.10/dist-packages (1.3.9)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.2.2)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.25.2)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.4.7)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import gdown\n",
        "import zipfile\n",
        "import cv2\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shutil\n",
        "import rasterio\n",
        "import rasterio.plot\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from keras.utils import Sequence, to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.transform import resize\n",
        "from skimage.util import random_noise\n",
        "from scipy import ndimage\n",
        "from scipy.ndimage import label as nd_label\n",
        "from scipy.ndimage import generic_filter\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Additional code can be added here if needed"
      ],
      "metadata": {
        "id": "CeNbsirhU_KR"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train test split"
      ],
      "metadata": {
        "id": "2p0o5HxEcoI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths_2018 = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/*.tif\")\n",
        "image_paths_2019 = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2019/*.tif\")\n",
        "image_paths_2020 = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2020/*.tif\")\n",
        "dem_path = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/dem/*.tif\")\n",
        "nwi_ccap_path = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/*.tif\")\n",
        "label_paths = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/ccap_filled/*.tif\")"
      ],
      "metadata": {
        "id": "f_4Fqb03fRBA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "implementing the training set, validation set, and test set split to begin"
      ],
      "metadata": {
        "id": "CtvAklgmqaN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "h4JRGj6Ooe0d"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_id(file_path):\n",
        "    # This function extracts the numeric identifier from a file path, assuming the format you provided\n",
        "    return int(os.path.basename(file_path).split('_')[0])\n",
        "\n",
        "# Create a unified list of identifiers from your labeled dataset, assuming nwi_ccap_path holds all possible labels\n",
        "identifiers = [extract_id(path) for path in nwi_ccap_path]\n",
        "\n",
        "# Split identifiers into training, validation, and test sets\n",
        "train_ids, temp_ids = train_test_split(identifiers, test_size=0.3, random_state=42)\n",
        "validation_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)\n",
        "\n",
        "# Function to split paths based on their identifiers\n",
        "def split_paths(paths, ids_set):\n",
        "    return [path for path in paths if extract_id(path) in ids_set]"
      ],
      "metadata": {
        "id": "y4TmYT5_oin3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat the above step for image_paths_2019, image_paths_2020, dem_path, nwi_ccap_path, etc.\n",
        "# Now you have all your datasets split into training, validation, and test sets by their paths\n",
        "# The next steps involve loading these paths into your model for training, which can be done using data generators or similar methods\n",
        "# Now, split all your datasets according to these ids\n",
        "train_image_paths_2018 = split_paths(image_paths_2018, set(train_ids))\n",
        "validation_image_paths_2018 = split_paths(image_paths_2018, set(validation_ids))\n",
        "test_image_paths_2018 = split_paths(image_paths_2018, set(test_ids))\n",
        "\n",
        "# Now, split all your datasets according to these ids\n",
        "train_image_paths_2019 = split_paths(image_paths_2019, set(train_ids))\n",
        "validation_image_paths_2019 = split_paths(image_paths_2019, set(validation_ids))\n",
        "test_image_paths_2019 = split_paths(image_paths_2019, set(test_ids))\n",
        "\n",
        "# Now, split all your datasets according to these ids\n",
        "train_image_paths_2020 = split_paths(image_paths_2020, set(train_ids))\n",
        "validation_image_paths_2020 = split_paths(image_paths_2020, set(validation_ids))\n",
        "test_image_paths_2020 = split_paths(image_paths_2020, set(test_ids))\n",
        "\n",
        "# Now, split all your datasets according to these ids\n",
        "train_dem_path = split_paths(dem_path, set(train_ids))\n",
        "validation_dem_path = split_paths(dem_path, set(validation_ids))\n",
        "test_dem_path = split_paths(dem_path, set(test_ids))\n",
        "\n",
        "# Now, split all your datasets according to these ids\n",
        "train_nwi_ccap_path = split_paths(nwi_ccap_path, set(train_ids))\n",
        "validation_nwi_ccap_path = split_paths(nwi_ccap_path, set(validation_ids))\n",
        "test_nwi_ccap_path = split_paths(nwi_ccap_path, set(test_ids))"
      ],
      "metadata": {
        "id": "t8CaM_2yo9U6"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "mapping each identifier to its corresponding file paths across the imagery, elevation, and labels datasets before the split."
      ],
      "metadata": {
        "id": "Q9G43XT7hyZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_id(file_path):\n",
        "    return int(os.path.basename(file_path).split('_')[0])\n",
        "\n",
        "# Step 1: Map Identifiers to File Paths for each dataset\n",
        "image_paths_2018_dict = {extract_id(path): path for path in image_paths_2018}\n",
        "dem_paths_dict = {extract_id(path): path for path in dem_path}\n",
        "labels_paths_dict = {extract_id(path): path for path in nwi_ccap_path}\n",
        "\n",
        "# Step 2: Ensure a unified list of identifiers (assuming all identifiers must exist across all datasets)\n",
        "all_identifiers = set(image_paths_2018_dict.keys()) & set(dem_paths_dict.keys()) & set(labels_paths_dict.keys())\n",
        "all_identifiers = list(all_identifiers)  # Convert to list for splitting\n",
        "\n",
        "# Step 3: Split Identifiers into training, validation, and test sets\n",
        "train_ids, temp_ids = train_test_split(all_identifiers, test_size=0.3, random_state=42)\n",
        "validation_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)\n",
        "\n",
        "# Step 4: Group Paths by Split\n",
        "def get_paths_for_ids(id_list, path_dict):\n",
        "    return [path_dict[id] for id in id_list]\n",
        "\n",
        "train_image_paths_2018 = get_paths_for_ids(train_ids, image_paths_2018_dict)\n",
        "validation_image_paths_2018 = get_paths_for_ids(validation_ids, image_paths_2018_dict)\n",
        "test_image_paths_2018 = get_paths_for_ids(test_ids, image_paths_2018_dict)\n",
        "\n",
        "# dem_path\n",
        "train_dem_paths = get_paths_for_ids(train_ids, dem_paths_dict)\n",
        "validation_dem_paths = get_paths_for_ids(validation_ids, dem_paths_dict)\n",
        "test_dem_paths = get_paths_for_ids(test_ids, dem_paths_dict)\n",
        "\n",
        "# nwi_ccap_path\n",
        "train_labels_paths = get_paths_for_ids(train_ids, labels_paths_dict)\n",
        "validation_labels_paths = get_paths_for_ids(validation_ids, labels_paths_dict)\n",
        "test_labels_paths = get_paths_for_ids(test_ids, labels_paths_dict)\n"
      ],
      "metadata": {
        "id": "CMA4F3Ouh03w"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if they match\n",
        "print(train_image_paths_2018[50])\n",
        "print(train_dem_paths[50])\n",
        "print(train_labels_paths[50])\n",
        "\n",
        "print(train_image_paths_2018[77])\n",
        "print(train_dem_paths[77])\n",
        "print(train_labels_paths[77])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOnRvGcQpJNO",
        "outputId": "37c8a5a9-a97a-4f56-dc68-5009ab95ab7d"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/12_planet.tif\n",
            "/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/dem/12_dem.tif\n",
            "/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/12_nwi_ccap_filled.tif\n",
            "/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/82_planet.tif\n",
            "/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/dem/82_dem.tif\n",
            "/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/82_nwi_ccap_filled.tif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def load_image(path, color_mode='rgb', target_size=(128, 128)):\n",
        "    with Image.open(path) as img:\n",
        "        if color_mode == 'grayscale':\n",
        "            img = img.convert('L')  # Convert to grayscale\n",
        "        else:\n",
        "            img = img.convert('RGB')  # Ensure RGB\n",
        "        img = img.resize(target_size)\n",
        "        return np.array(img)\n"
      ],
      "metadata": {
        "id": "wU_2lYMdpQHQ"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade tensorflow\n"
      ],
      "metadata": {
        "id": "ne6Pjubfz9n8",
        "outputId": "f30140bf-f4fa-4ceb-eca5-4a8b66d0e739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: tensorflow\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "Successfully installed tensorflow-2.15.0.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              },
              "id": "2fe8c184288e43fb9b138ba85d0fd692"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_image(\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/203_planet.tif\")"
      ],
      "metadata": {
        "id": "4bqhT2biziX8",
        "outputId": "a93965fa-afab-459a-b2b5-c8f90cf6ecbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "cannot identify image file '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/203_planet.tif'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-146-c2d07134b520>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/203_planet.tif\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-144-c9e1e98c5b95>\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(path, color_mode, target_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3281\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3283\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mUnidentifiedImageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/203_planet.tif'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "import numpy as np\n",
        "\n",
        "def load_image_rasterio(path, target_size=(384, 384)):\n",
        "    with rasterio.open(path) as src:\n",
        "        # Read the dataset's first band only\n",
        "        band1 = src.read(1)\n",
        "\n",
        "        # Resize image to target size using PIL (as an example, you may need to adjust this depending on your exact requirements)\n",
        "        img = Image.fromarray(band1)\n",
        "        img = img.resize(target_size)\n",
        "        return np.array(img)\n",
        "\n",
        "# Example usage\n",
        "img_array = load_image_rasterio(\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/203_planet.tif\")\n"
      ],
      "metadata": {
        "id": "MmJt3QK20FDS"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_array"
      ],
      "metadata": {
        "id": "kfDZi5kT0YMt",
        "outputId": "6112d3dc-cf67-4a8b-9313-22b9d67007d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[384., 384., 384., ..., 348., 348., 348.],\n",
              "       [384., 384., 384., ..., 348., 348., 348.],\n",
              "       [384., 384., 384., ..., 348., 348., 348.],\n",
              "       ...,\n",
              "       [503., 503., 503., ..., 373., 373., 373.],\n",
              "       [503., 503., 503., ..., 373., 373., 373.],\n",
              "       [503., 503., 503., ..., 373., 373., 373.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " set up a data loader for my structured data, considering the additional elevation channel"
      ],
      "metadata": {
        "id": "cA9Lo_NFqfAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ],
      "metadata": {
        "id": "_OaO7Ldfqh1X"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class MultiChannelDataGenerator(Sequence):\n",
        "#     def __init__(self, image_paths, elevation_paths, labels_paths, batch_size=32, dim=(128, 128), n_channels=5, n_classes=11, shuffle=True):\n",
        "#         'Initialization'\n",
        "#         self.dim = dim\n",
        "#         self.batch_size = batch_size\n",
        "#         self.image_paths = image_paths\n",
        "#         self.elevation_paths = elevation_paths\n",
        "#         self.labels_paths = labels_paths\n",
        "#         self.n_channels = n_channels\n",
        "#         self.n_classes = n_classes\n",
        "#         self.shuffle = shuffle\n",
        "#         self.indexes = np.arange(len(self.image_paths))\n",
        "#         self.on_epoch_end()\n",
        "\n",
        "#     def __len__(self):\n",
        "#         'Denotes the number of batches per epoch'\n",
        "#         return int(np.floor(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         'Generate one batch of data'\n",
        "#         # Generate indexes of the batch\n",
        "#         indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "#         # # Find list of IDs\n",
        "#         # list_image_temp = [self.image_paths[k] for k in indexes]\n",
        "#         # list_elevation_temp = [self.elevation_paths[k] for k in indexes]\n",
        "#         # list_labels_temp = [self.labels_paths[k] for k in indexes]\n",
        "\n",
        "#         # # Generate data\n",
        "#         # X, y = self.__data_generation(list_image_temp, list_elevation_temp, list_labels_temp)\n",
        "#         # return X, y\n",
        "\n",
        "#         # Lists of paths for the current batch\n",
        "#         batch_image_paths = [self.image_paths[k] for k in indexes]\n",
        "#         batch_elevation_paths = [self.elevation_paths[k] for k in indexes]\n",
        "#         batch_labels_paths = [self.labels_paths[k] for k in indexes]\n",
        "\n",
        "#         # Generate data\n",
        "#         X, y = self.__data_generation(batch_image_paths, batch_elevation_paths, batch_labels_paths)\n",
        "\n",
        "#         return X, y\n",
        "\n",
        "#     # def on_epoch_end(self):\n",
        "#     #     'Updates indexes after each epoch'\n",
        "#     #     self.indexes = np.arange(len(self.image_paths))\n",
        "#     #     if self.shuffle == True:\n",
        "#     #         np.random.shuffle(self.indexes)\n",
        "\n",
        "#     def on_epoch_end(self):\n",
        "#         'Updates indexes after each epoch'\n",
        "#         if self.shuffle:\n",
        "#             np.random.shuffle(self.indexes)\n",
        "\n",
        "#     # def __data_generation(self, list_image_temp, list_elevation_temp, list_labels_temp):\n",
        "#     def __data_generation(self, batch_image_paths, batch_elevation_paths, batch_labels_paths):\n",
        "#         'Generates data containing batch_size samples'\n",
        "#         # Initialization\n",
        "#         X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "#         # y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n",
        "#         y = np.empty((self.batch_size, *self.dim), dtype=int)\n",
        "\n",
        "#         # Generate data\n",
        "#         # for i, (img_path, elev_path, label_path) in enumerate(zip(list_image_temp, list_elevation_temp, list_labels_temp)):\n",
        "#         for i, (img_path, elev_path, label_path) in enumerate(zip(batch_image_paths, batch_elevation_paths, batch_labels_paths)):\n",
        "#             # Store sample\n",
        "#             img = load_img(img_path, color_mode='rgba', target_size=self.dim)\n",
        "#             img = img_to_array(img)[:,:,:4]  # Ensure img has only 4 channels (RGBA or RGBNIR)\n",
        "#             # img = img_to_array(img) # This will be (128, 128, 3) for RGB\n",
        "\n",
        "#             # Store elevation\n",
        "\n",
        "#             elevation = load_img(elev_path, color_mode='grayscale', target_size=self.dim)\n",
        "#             elevation = img_to_array(elevation) # This will be (128, 128, 1) for elevation\n",
        "#             # elevation = np.repeat(elevation, 4, axis=-1)  # Repeat elevation across what would be the color channels to match dimensions (NOT sure if I need this..?)\n",
        "\n",
        "#             img_elev = np.concatenate((img, elevation), axis=-1) # Stack to form a 5-chanel input\n",
        "\n",
        "#             # X[i,] = np.concatenate((img, elevation), axis=-1)\n",
        "#             X[i, ] = img_elev\n",
        "\n",
        "\n",
        "#             # # Store class\n",
        "#             # label = load_img(label_path, color_mode='grayscale', target_size=self.dim)\n",
        "#             # label = img_to_array(label)\n",
        "#             # y[i] = tf.keras.utils.to_categorical(label, num_classes=self.n_classes)\n",
        "\n",
        "#             # For labels, assuming they are single-channel images where the pixel value represents the class\n",
        "#             label = load_img(label_path, color_mode='grayscale', target_size=self.dim)\n",
        "#             label = img_to_array(label)\n",
        "#             label = label[:,:,0]  # Convert to (128, 128) array\n",
        "#             y[i,] = label\n",
        "\n",
        "#         # return X, np.argmax(y, axis=-1)\n",
        "\n",
        "#         # Convert y to one-hot encoding\n",
        "#         y = tf.keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
        "\n",
        "\n",
        "\n",
        "#         return X, y\n"
      ],
      "metadata": {
        "id": "WClXE5_HqkFm"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_normalize(array):\n",
        "    max_value = np.nanmax(array)  # Use nanmax to ignore NaN values for the max calculation\n",
        "    if max_value > 0:\n",
        "        return np.clip(array / max_value, 0, 1)  # Normalize only if max_value is positive\n",
        "    else:\n",
        "        return np.zeros(array.shape)  # Return an array of zeros if max_value is non-positive\n"
      ],
      "metadata": {
        "id": "qBwlZrCr1_mQ"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_unique_classes_geospatial(label_paths):\n",
        "    unique_values = set()\n",
        "    for label_path in label_paths:\n",
        "        with rasterio.open(label_path) as dataset:\n",
        "            label_array = dataset.read(1)  # Assuming labels are in the first band\n",
        "            unique_values.update(np.unique(label_array))\n",
        "    return unique_values\n",
        "\n",
        "# Example usage with rasterio for geospatial images\n",
        "label_paths = ['/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/100_nwi_ccap_filled.tif',\n",
        "               '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/11_nwi_ccap_filled.tif',\n",
        "               '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/127_nwi_ccap_filled.tif',\n",
        "               \"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/158_nwi_ccap_filled.tif\",\n",
        "               \"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/179_nwi_ccap_filled.tif\",\n",
        "               \"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/205_nwi_ccap_filled.tif\",\n",
        "               \"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/208_nwi_ccap_filled.tif\",\n",
        "               \"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/220_nwi_ccap_filled.tif\"]  # Add all your label paths here\n",
        "unique_classes = find_unique_classes_geospatial(label_paths)\n",
        "print(f\"Unique label values (classes): {unique_classes}\")\n"
      ],
      "metadata": {
        "id": "kP2rhoSS5sSn",
        "outputId": "44381ac5-523d-4b54-8d19-9892bf60b599",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique label values (classes): {0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(unique_classes)\n",
        "print(f\"Total number of classes: {num_classes}\")"
      ],
      "metadata": {
        "id": "bMNQlFzn6XUV",
        "outputId": "00e6a091-1683-48ef-9062-084b07e84f38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of classes: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import rasterio\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "class MultiChannelDataGenerator(Sequence):\n",
        "    def __init__(self, image_paths, elevation_paths, labels_paths, batch_size=32, dim=(384, 384), n_channels=5, n_classes=12, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.image_paths = image_paths\n",
        "        self.elevation_paths = elevation_paths\n",
        "        self.labels_paths = labels_paths\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(indexes)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.image_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, indexes):\n",
        "    # def __data_generation(self, batch_image_paths, batch_elevation_paths, batch_labels_paths):\n",
        "\n",
        "        'Generates data containing batch_size samples'\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        y = np.empty((self.batch_size, *self.dim), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, idx in enumerate(indexes):\n",
        "            # Load satellite image\n",
        "            with rasterio.open(self.image_paths[idx]) as src:\n",
        "                img = src.read([1, 2, 3, 4])  # Assuming RGBNIR channels are 1-4\n",
        "                img = np.moveaxis(img, 0, -1)  # Move channels from first to last dimension\n",
        "                img = np.clip(img / 255.0, 0, 1)  # Normalize to [0, 1]\n",
        "\n",
        "            # Load elevation data\n",
        "            with rasterio.open(self.elevation_paths[idx]) as src:\n",
        "                elevation = src.read(1)  # Read the single band\n",
        "                elevation = np.expand_dims(elevation, axis=-1)  # Add channel dimension\n",
        "                # elevation = np.clip(elevation / np.max(elevation), 0, 1)  # Normalize\n",
        "                # Then, inside your data generation function, replace the normalization line for elevation with:\n",
        "                elevation = safe_normalize(elevation)\n",
        "\n",
        "            # Combine image and elevation data\n",
        "            X[i,] = np.concatenate((img, elevation), axis=-1)\n",
        "\n",
        "            # Load label\n",
        "            with rasterio.open(self.labels_paths[idx]) as src:\n",
        "                label = src.read(1)\n",
        "                label -= 1  # Subtract 1 to convert to 0-based indexing\n",
        "                y[i,] = label\n",
        "\n",
        "        # One-hot encode labels\n",
        "        # y = np.reshape(y, (-1, *self.dim))\n",
        "        # y = to_categorical(y, num_classes=self.n_classes)\n",
        "        y = tf.keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
        "\n",
        "        return X, y\n",
        "\n"
      ],
      "metadata": {
        "id": "NFlYRgRq0ynT"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_image_paths_2018\n",
        "# validation_image_paths_2018\n",
        "# test_image_paths_2018\n",
        "# train_dem_paths\n",
        "# validation_dem_paths\n",
        "# test_dem_paths\n",
        "# train_labels_paths\n",
        "# validation_labels_paths\n",
        "# test_labels_paths"
      ],
      "metadata": {
        "id": "wDD2qu2Mj1e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_image_paths_2018"
      ],
      "metadata": {
        "id": "uCUjtnCek5KH"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_image_paths_2018\n",
        "# validation_image_paths_2018\n",
        "# test_image_paths_2018\n",
        "# train_dem_paths\n",
        "# validation_dem_paths\n",
        "# test_dem_paths\n",
        "# train_labels_paths\n",
        "# validation_labels_paths\n",
        "# test_labels_paths\n",
        "\n",
        "train_generator = MultiChannelDataGenerator(train_image_paths_2018, train_dem_paths, train_labels_paths, batch_size=16, n_classes=12)\n",
        "validation_generator = MultiChannelDataGenerator(validation_image_paths_2018, validation_dem_paths, validation_labels_paths, batch_size=16, n_classes=12)\n",
        "\n"
      ],
      "metadata": {
        "id": "7-zDTGqocq3u"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate, Activation\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "VBtwdPI2d4uB"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_model(input_size=(384, 384, 5), n_classes=12):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Contracting Path\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
        "\n",
        "    # Expansive Path\n",
        "    up6 = Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(conv5)\n",
        "    merge6 = concatenate([up6, conv4], axis=3)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
        "    merge7 = concatenate([up7, conv3], axis=3)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n",
        "    merge8 = concatenate([up8, conv2], axis=3)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n",
        "    merge9 = concatenate([up9, conv1], axis=3)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "\n",
        "    # Output Layer\n",
        "    conv10 = Conv2D(n_classes, 1, activation='softmax')(conv9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Ug3CquCErqwV"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = unet_model(input_size=(384, 384, 5), n_classes=12)\n",
        "# model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=11)])\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "uzvS7hPmeV9s",
        "outputId": "b623c4c2-3b17-4821-b080-bdfbe34de6e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary() # Total params: 31,033,612"
      ],
      "metadata": {
        "id": "rlXdnSHPecsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume 'model' is your compiled U-Net model\n",
        "# train_generator_2018\n",
        "# validation_generator_2018\n",
        "\n",
        "# model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
        "\n",
        "# Assuming train_generator and validation_generator are already instantiated and ready\n",
        "model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
        "\n"
      ],
      "metadata": {
        "id": "oEdfTru8eo06",
        "outputId": "0d558b4a-656a-4368-9d03-0465d2422347",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_paths_2018"
      ],
      "metadata": {
        "id": "z3yQigmfyzkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# # Replace 'some_image_path' with the actual path to an image file\n",
        "# try:\n",
        "#     img = Image.open( '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/200_planet.tif')\n",
        "#     img.verify()  # Verify that this is a valid image\n",
        "# except Exception as e:\n",
        "#     print(f\"Error opening image: {e}\")\n",
        "# # /content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/200_planet.tif\n",
        "\n",
        "\n",
        "# Replace 'some_image_path' with the actual path to an image file\n",
        "try:\n",
        "    img = Image.open( '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/200_planet.tif')\n",
        "    img.verify()  # Verify that this is a valid image\n",
        "except Exception as e:\n",
        "    print(f\"Error opening image: {e}\")"
      ],
      "metadata": {
        "id": "GUwZ6Lv9yt92",
        "outputId": "69fad051-0240-44ae-9c39-5114fa4ae3d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error opening image: cannot identify image file '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/200_planet.tif'\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "qNs35wu6fI86"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "source": [
        "# Print the first 5 elements of list_image_temp\n",
        "print(train_image_paths_2018[:5])\n",
        "\n",
        "# Print the first 5 elements of list_elevation_temp\n",
        "print(train_dem_path[:5])\n",
        "\n",
        "# Print the first 5 elements of list_labels_temp\n",
        "print(train_nwi_ccap_path[:5])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "oMIjxk9FfJ2x",
        "outputId": "26eb7c87-ba00-4e51-e617-d91c4b488ed0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/7_planet.tif', '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/100_planet.tif', '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/55_planet.tif', '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/35_planet.tif', '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/50_planet.tif']\n",
            "['/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/dem/28_dem.tif', '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/dem/121_dem.tif', '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/dem/127_dem.tif', '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/dem/124_dem.tif', '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/dem/197_dem.tif']\n",
            "['/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/23_nwi_ccap_filled.tif', '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/184_nwi_ccap_filled.tif', '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/20_nwi_ccap_filled.tif', '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/58_nwi_ccap_filled.tif', '/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/116_nwi_ccap_filled.tif']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "end"
      ],
      "metadata": {
        "id": "8PYvjX7rcrfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, image_files, label_files, img_height, img_width, batch_size, num_classes):\n",
        "        self.image_files = image_files\n",
        "        self.label_files = label_files\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        # self.noise = noise\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_files) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_batch_files = self.image_files[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "        label_batch_files = self.label_files[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "\n",
        "        batch_images, batch_labels = self.load_images_and_labels(image_batch_files,label_batch_files)\n",
        "        return batch_images, batch_labels\n",
        "\n",
        "    def load_and_reshape_image(self, image_path):\n",
        "        with rasterio.open(image_path) as src:\n",
        "            image = src.read()\n",
        "            image = image.transpose((1, 2, 0))\n",
        "            if image.shape[0] != self.img_height or image.shape[1] != self.img_width:\n",
        "                image = cv2.resize(image, (self.img_width, self.img_height), interpolation=cv2.INTER_NEAREST)\n",
        "            if len(image.shape) == 3 and image.shape[2] == 1:\n",
        "                image = np.squeeze(image, axis=2)\n",
        "\n",
        "            return image\n",
        "\n",
        "    def load_images_and_labels(self, image_files, label_files):\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for image_file in image_files:\n",
        "            image = self.load_and_reshape_image(image_file)\n",
        "            # image[image <= -3e+38] = np.nan\n",
        "\n",
        "            # # # Replace NaN values with the mean of the non-NaN pixels\n",
        "            # if np.any(np.isnan(image)):\n",
        "            #     nan_mask = np.isnan(image)\n",
        "            #     image[nan_mask] = np.nanmean(image)\n",
        "\n",
        "            # # # Replace Inf values with the mean of the non-Inf pixels\n",
        "            # if np.any(np.isinf(image)):\n",
        "            #     inf_mask = np.isinf(image)\n",
        "            #     image[inf_mask] = np.nanmean(image)\n",
        "\n",
        "            # # Convert to float\n",
        "            # image = image.astype(np.float32)\n",
        "\n",
        "            # # Z-score normalization\n",
        "            # mean = np.mean(image, axis=(0, 1), keepdims=True)\n",
        "            # std = np.std(image, axis=(0, 1), keepdims=True)\n",
        "            # # mean[mean < 0]\n",
        "            # std[std < 0] = 0\n",
        "\n",
        "            # # Normalize with epsilon to prevent divide by zero\n",
        "            # epsilon = 1e-7\n",
        "\n",
        "            # image = (image - mean) / (std + epsilon)\n",
        "\n",
        "            images.append(image)\n",
        "\n",
        "        for label_file in label_files:\n",
        "            # label_file = image_file.replace(\"planet\", \"ccap_filled\").replace('images_2018','ccap_filled')\n",
        "            label = self.load_and_reshape_image(label_file)\n",
        "            # label[label <= -3e+38] = np.nan\n",
        "\n",
        "            # # # Replace NaN values with the mean of the non-NaN pixels\n",
        "            # if np.any(np.isnan(label)):\n",
        "            #     nan_mask = np.isnan(label)\n",
        "            #     label[nan_mask] = 12\n",
        "\n",
        "            # # # Replace Inf values with the mean of the non-Inf pixels\n",
        "            # if np.any(np.isinf(label)):\n",
        "            #     inf_mask = np.isinf(label)\n",
        "            #     label[inf_mask] = 12\n",
        "\n",
        "            label -= 1\n",
        "            label = label.astype(np.int8)\n",
        "            label = to_categorical(label, num_classes=self.num_classes)\n",
        "            labels.append(label)\n",
        "\n",
        "        return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "ZGapBsD-T4zX"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_paths = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm4/images_2018/*.tif\")\n",
        "train_label_paths = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm4/ccap_filled/*.tif\")\n",
        "\n",
        "# val_image_paths = glob.glob(f\"{base_dir}/validation/image/*.tif\")\n",
        "# val_label_paths = glob.glob(f\"{base_dir}/validation/label/*.tif\")"
      ],
      "metadata": {
        "id": "pI1Wn2EDWfzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_label_paths[0])\n",
        "train_image_paths[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "5-3jmoCAWx15",
        "outputId": "f0227e45-066b-47ae-c18a-a5204b0576b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm4/ccap_filled/3_ccap_filled.tif\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm4/images_2018/1814_planet.tif'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm4/images_2018"
      ],
      "metadata": {
        "id": "n7VYRQYfV-m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_gen_test = DataGenerator(sum_df['Images_path'][0:5], sum_df['Labels_path'][0:5], 512, 512, 2, 22)\n",
        "# Create the data generator\n",
        "training_data_generator = DataGenerator(train_image_paths, train_label_paths, 128, 128, 4, 12)\n",
        "# validation_data_generator = DataGenerator(sum_df['Images_path'][sum_df['random_split']==1], sum_df['Labels_path'][sum_df['random_split']==1], 512, 512, 4, 25)\n"
      ],
      "metadata": {
        "id": "yCwfJD8nViEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm4/ccap_filled/1004_ccap_filled.tif"
      ],
      "metadata": {
        "id": "Xr38sNZ5ZGun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_images, batch_labels = training_data_generator.__getitem__(0)"
      ],
      "metadata": {
        "id": "oY0rx_yqX3hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_model(img_size,num_bands, num_classes):\n",
        "#     inputs = keras.Input(shape=(img_size[0], img_size[1], num_bands))  # Change the number of channels to 4\n",
        "\n",
        "#     # Entry block\n",
        "#     x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "#     x = layers.BatchNormalization()(x)\n",
        "#     x = layers.Activation(\"LeakyReLU\")(x)\n",
        "\n",
        "#     previous_block_activation = x  # Set aside residual\n",
        "\n",
        "#     # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "#     for filters in [64, 128, 256]:\n",
        "#         x = layers.Activation(\"LeakyReLU\")(x)\n",
        "#         x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         x = layers.Activation(\"LeakyReLU\")(x)\n",
        "#         x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "#         # Project residual\n",
        "#         residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "#             previous_block_activation\n",
        "#         )\n",
        "#         x = layers.add([x, residual])  # Add back residual\n",
        "#         previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "#     for filters in [256, 128, 64, 32]:\n",
        "#         x = layers.Activation(\"LeakyReLU\")(x)\n",
        "#         x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         x = layers.Activation(\"LeakyReLU\")(x)\n",
        "#         x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "#         residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "#         residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "#         x = layers.add([x, residual])  # Add back residual\n",
        "#         previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "#     # Add a per-pixel classification layer\n",
        "#     outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "#     # Define the model\n",
        "#     model = keras.Model(inputs, outputs)\n",
        "#     model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # updated to sparse categorical cross-entropy loss\n",
        "#     return model"
      ],
      "metadata": {
        "id": "9HXLq2bqarAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "# from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "\n",
        "# from tensorflow.keras.layers import BatchNormalization\n",
        "# from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "# from tensorflow.python.keras.layers import BatchNormalization\n",
        "\n",
        "# U-Net model for image segmentation.\n",
        "# Encoder and decoder conncted by a center block.\n",
        "# Encoder downsamples the input image while capturing its features.\n",
        "# Decoder upsamples the encoded image to generate a segmentation map.\n",
        "\n",
        "def conv_block(input_tensor, num_filters):\n",
        "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
        "\tencoder = layers.BatchNormalization()(encoder)\n",
        "\tencoder = layers.Activation('LeakyReLU')(encoder) # from relu to LeakyReLU\n",
        "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
        "\tencoder = layers.BatchNormalization()(encoder)\n",
        "\tencoder = layers.Activation('LeakyReLU')(encoder) # from relu to LeakyReLU\n",
        "\treturn encoder\n",
        "\n",
        "def encoder_block(input_tensor, num_filters):\n",
        "\tencoder = conv_block(input_tensor, num_filters)\n",
        "\tencoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
        "\treturn encoder_pool, encoder\n",
        "\n",
        "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
        "\tdecoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
        "\tdecoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('LeakyReLU')(decoder) # from relu to LeakyReLU\n",
        "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('LeakyReLU')(decoder) # from relu to LeakyReLU\n",
        "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('LeakyReLU')(decoder) # from relu to LeakyReLU\n",
        "\treturn decoder\n",
        "\n",
        "def get_model():\n",
        "\tinputs = layers.Input(shape=[KERNEL_SIZE, KERNEL_SIZE, len(BANDS)]) # 256\n",
        "\tencoder0_pool, encoder0 = encoder_block(inputs, 32) # 128\n",
        "\tencoder1_pool, encoder1 = encoder_block(encoder0_pool, 64) # 64\n",
        "\tencoder2_pool, encoder2 = encoder_block(encoder1_pool, 128) # 32\n",
        "\tencoder3_pool, encoder3 = encoder_block(encoder2_pool, 256) # 16\n",
        "\tencoder4_pool, encoder4 = encoder_block(encoder3_pool, 512) # 8\n",
        "\tcenter = conv_block(encoder4_pool, 1024) # center\n",
        "\tdecoder4 = decoder_block(center, encoder4, 512) # 16\n",
        "\tdecoder3 = decoder_block(decoder4, encoder3, 256) # 32\n",
        "\tdecoder2 = decoder_block(decoder3, encoder2, 128) # 64\n",
        "\tdecoder1 = decoder_block(decoder2, encoder1, 64) # 128\n",
        "\tdecoder0 = decoder_block(decoder1, encoder0, 32) # 256\n",
        "\toutputs = layers.Conv2D(CLASSES, (1, 1), activation='softmax')(decoder0) # kept because this is a multiclass classification\n",
        "\n",
        "\tmodel = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "\tmodel.compile(\n",
        "\t\toptimizer=optimizers.get(OPTIMIZER),\n",
        "\t\tloss=losses.get(LOSS),\n",
        "\t\tmetrics=[metrics.get(metric) for metric in METRICS])\n",
        "\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "WOU26Rp1chre"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KERNEL_SIZE = 128\n",
        "CLASSES = 12\n",
        "BANDS = range(4)\n",
        "KERNEL_SHAPE = [128, 128]\n",
        "OPTIMIZER = 'adam'\n",
        "LOSS = 'categorical_crossentropy'\n",
        "METRICS = ['categorical_accuracy']"
      ],
      "metadata": {
        "id": "7MYIse8Lc9qy"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import TenserFlow classes and functions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "NzskjnjKdRID"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = create_model([128,128],4,11)\n",
        "model = get_model()"
      ],
      "metadata": {
        "id": "8PJpkjavbr5u"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20VM6nuhg_si",
        "outputId": "933be260-8281-40e7-8f34-24410e0f11e4"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, 128, 128, 4)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)          (None, 128, 128, 32)         1184      ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 128, 128, 32)         128       ['conv2d_75[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_27 (Activation)  (None, 128, 128, 32)         0         ['batch_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)          (None, 128, 128, 32)         9248      ['activation_27[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 128, 128, 32)         128       ['conv2d_76[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_28 (Activation)  (None, 128, 128, 32)         0         ['batch_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_15 (MaxPooli  (None, 64, 64, 32)           0         ['activation_28[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)          (None, 64, 64, 64)           18496     ['max_pooling2d_15[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (Ba  (None, 64, 64, 64)           256       ['conv2d_77[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_29 (Activation)  (None, 64, 64, 64)           0         ['batch_normalization_29[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)          (None, 64, 64, 64)           36928     ['activation_29[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_30 (Ba  (None, 64, 64, 64)           256       ['conv2d_78[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_30 (Activation)  (None, 64, 64, 64)           0         ['batch_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_16 (MaxPooli  (None, 32, 32, 64)           0         ['activation_30[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)          (None, 32, 32, 128)          73856     ['max_pooling2d_16[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_31 (Ba  (None, 32, 32, 128)          512       ['conv2d_79[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_31 (Activation)  (None, 32, 32, 128)          0         ['batch_normalization_31[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)          (None, 32, 32, 128)          147584    ['activation_31[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_32 (Ba  (None, 32, 32, 128)          512       ['conv2d_80[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_32 (Activation)  (None, 32, 32, 128)          0         ['batch_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_17 (MaxPooli  (None, 16, 16, 128)          0         ['activation_32[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)          (None, 16, 16, 256)          295168    ['max_pooling2d_17[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (Ba  (None, 16, 16, 256)          1024      ['conv2d_81[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_33 (Activation)  (None, 16, 16, 256)          0         ['batch_normalization_33[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)          (None, 16, 16, 256)          590080    ['activation_33[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 16, 16, 256)          1024      ['conv2d_82[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_34 (Activation)  (None, 16, 16, 256)          0         ['batch_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_18 (MaxPooli  (None, 8, 8, 256)            0         ['activation_34[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)          (None, 8, 8, 512)            1180160   ['max_pooling2d_18[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_35 (Ba  (None, 8, 8, 512)            2048      ['conv2d_83[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_35 (Activation)  (None, 8, 8, 512)            0         ['batch_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)          (None, 8, 8, 512)            2359808   ['activation_35[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_36 (Ba  (None, 8, 8, 512)            2048      ['conv2d_84[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_36 (Activation)  (None, 8, 8, 512)            0         ['batch_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_19 (MaxPooli  (None, 4, 4, 512)            0         ['activation_36[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)          (None, 4, 4, 1024)           4719616   ['max_pooling2d_19[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (Ba  (None, 4, 4, 1024)           4096      ['conv2d_85[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_37 (Activation)  (None, 4, 4, 1024)           0         ['batch_normalization_37[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)          (None, 4, 4, 1024)           9438208   ['activation_37[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_38 (Ba  (None, 4, 4, 1024)           4096      ['conv2d_86[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_38 (Activation)  (None, 4, 4, 1024)           0         ['batch_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_15 (Conv2  (None, 8, 8, 512)            2097664   ['activation_38[0][0]']       \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenat  (None, 8, 8, 1024)           0         ['activation_36[0][0]',       \n",
            " e)                                                                  'conv2d_transpose_15[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_39 (Ba  (None, 8, 8, 1024)           4096      ['concatenate_15[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_39 (Activation)  (None, 8, 8, 1024)           0         ['batch_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)          (None, 8, 8, 512)            4719104   ['activation_39[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_40 (Ba  (None, 8, 8, 512)            2048      ['conv2d_87[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_40 (Activation)  (None, 8, 8, 512)            0         ['batch_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)          (None, 8, 8, 512)            2359808   ['activation_40[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_41 (Ba  (None, 8, 8, 512)            2048      ['conv2d_88[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_41 (Activation)  (None, 8, 8, 512)            0         ['batch_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_16 (Conv2  (None, 16, 16, 256)          524544    ['activation_41[0][0]']       \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenat  (None, 16, 16, 512)          0         ['activation_34[0][0]',       \n",
            " e)                                                                  'conv2d_transpose_16[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_42 (Ba  (None, 16, 16, 512)          2048      ['concatenate_16[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_42 (Activation)  (None, 16, 16, 512)          0         ['batch_normalization_42[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)          (None, 16, 16, 256)          1179904   ['activation_42[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_43 (Ba  (None, 16, 16, 256)          1024      ['conv2d_89[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_43 (Activation)  (None, 16, 16, 256)          0         ['batch_normalization_43[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)          (None, 16, 16, 256)          590080    ['activation_43[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_44 (Ba  (None, 16, 16, 256)          1024      ['conv2d_90[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_44 (Activation)  (None, 16, 16, 256)          0         ['batch_normalization_44[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_17 (Conv2  (None, 32, 32, 128)          131200    ['activation_44[0][0]']       \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " concatenate_17 (Concatenat  (None, 32, 32, 256)          0         ['activation_32[0][0]',       \n",
            " e)                                                                  'conv2d_transpose_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_45 (Ba  (None, 32, 32, 256)          1024      ['concatenate_17[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_45 (Activation)  (None, 32, 32, 256)          0         ['batch_normalization_45[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)          (None, 32, 32, 128)          295040    ['activation_45[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_46 (Ba  (None, 32, 32, 128)          512       ['conv2d_91[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_46 (Activation)  (None, 32, 32, 128)          0         ['batch_normalization_46[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)          (None, 32, 32, 128)          147584    ['activation_46[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_47 (Ba  (None, 32, 32, 128)          512       ['conv2d_92[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_47 (Activation)  (None, 32, 32, 128)          0         ['batch_normalization_47[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_18 (Conv2  (None, 64, 64, 64)           32832     ['activation_47[0][0]']       \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " concatenate_18 (Concatenat  (None, 64, 64, 128)          0         ['activation_30[0][0]',       \n",
            " e)                                                                  'conv2d_transpose_18[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (Ba  (None, 64, 64, 128)          512       ['concatenate_18[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_48 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_48[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)          (None, 64, 64, 64)           73792     ['activation_48[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_49 (Ba  (None, 64, 64, 64)           256       ['conv2d_93[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_49 (Activation)  (None, 64, 64, 64)           0         ['batch_normalization_49[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)          (None, 64, 64, 64)           36928     ['activation_49[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_50 (Ba  (None, 64, 64, 64)           256       ['conv2d_94[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_50 (Activation)  (None, 64, 64, 64)           0         ['batch_normalization_50[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_19 (Conv2  (None, 128, 128, 32)         8224      ['activation_50[0][0]']       \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " concatenate_19 (Concatenat  (None, 128, 128, 64)         0         ['activation_28[0][0]',       \n",
            " e)                                                                  'conv2d_transpose_19[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_51 (Ba  (None, 128, 128, 64)         256       ['concatenate_19[0][0]']      \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_51 (Activation)  (None, 128, 128, 64)         0         ['batch_normalization_51[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)          (None, 128, 128, 32)         18464     ['activation_51[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_52 (Ba  (None, 128, 128, 32)         128       ['conv2d_95[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_52 (Activation)  (None, 128, 128, 32)         0         ['batch_normalization_52[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)          (None, 128, 128, 32)         9248      ['activation_52[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_53 (Ba  (None, 128, 128, 32)         128       ['conv2d_96[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_53 (Activation)  (None, 128, 128, 32)         0         ['batch_normalization_53[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)          (None, 128, 128, 12)         396       ['activation_53[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31127148 (118.74 MB)\n",
            "Trainable params: 31111148 (118.68 MB)\n",
            "Non-trainable params: 16000 (62.50 KB)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "# train_image_paths_2018\n",
        "# validation_image_paths_2018\n",
        "# test_image_paths_2018\n",
        "# train_dem_paths\n",
        "# validation_dem_paths\n",
        "# test_dem_paths\n",
        "# train_labels_paths\n",
        "# validation_labels_paths\n",
        "# test_labels_paths\n",
        "# train_generator\n",
        "# validation_generator\n",
        "\n",
        "# model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy','categorical_accuracy'])\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"landcover_segmentation.h5\", save_best_only=True)\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "BTy_jam1bOnZ"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator, epochs=10, callbacks=callbacks,shuffle=True)"
      ],
      "metadata": {
        "id": "JecPJi2kx6ef",
        "outputId": "0cffdbda-ac87-4e56-f3f8-a228e7e036f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "cannot identify image file <_io.BytesIO object at 0x7bf945b2d080>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-01b7a12df787>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-120-0be5982a2ac1>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Generate data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_image_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_elevation_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-120-0be5982a2ac1>\u001b[0m in \u001b[0;36m__data_generation\u001b[0;34m(self, batch_image_paths, batch_elevation_paths, batch_labels_paths)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melev_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_image_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_elevation_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# Store sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgba'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Ensure img has only 4 channels (RGBA or RGBNIR)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# img = img_to_array(img) # This will be (128, 128, 3) for RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3281\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3283\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mUnidentifiedImageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7bf945b2d080>"
          ]
        }
      ]
    }
  ]
}