{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOwJrY+7kEl1Ck5wml+wmFr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MadmanMarble/MadmanMarble/blob/main/untet_working_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8zkhfI0TixX",
        "outputId": "58c37b80-2ea6-4953-9b6f-03fb244d97e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio scikit-image tensorflow keras gdown\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_yfvgB7VA5L",
        "outputId": "baf5bb14-aa33-4c76-8080-d96498b4d124"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.9-cp310-cp310-manylinux2014_x86_64.whl (20.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.2.2)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.25.2)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.9 snuggs-1.4.7\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import gdown\n",
        "import zipfile\n",
        "import cv2\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shutil\n",
        "import rasterio\n",
        "import rasterio.plot\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from keras.utils import Sequence, to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.transform import resize\n",
        "from skimage.util import random_noise\n",
        "from scipy import ndimage\n",
        "from scipy.ndimage import label as nd_label\n",
        "from scipy.ndimage import generic_filter\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Additional code can be added here if needed"
      ],
      "metadata": {
        "id": "CeNbsirhU_KR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train test split"
      ],
      "metadata": {
        "id": "2p0o5HxEcoI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# image_paths_2018 = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2018/*.tif\")\n",
        "# image_paths_2019 = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2019/*.tif\")\n",
        "# image_paths_2020 = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images_2020/*.tif\")\n",
        "# dem_path = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/dem/*.tif\")\n",
        "# nwi_ccap_path = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/nwi_ccap_filled/*.tif\")\n",
        "# label_paths = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/ccap_filled/*.tif\")"
      ],
      "metadata": {
        "id": "f_4Fqb03fRBA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "implementing the training set, validation set, and test set split to begin"
      ],
      "metadata": {
        "id": "CtvAklgmqaN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is pulling allllll the data in images and in labels. there's no split among them. need to do that now so I can have some in the validation.\n",
        "\n",
        "# train_image_paths = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/images/*.tif\")\n",
        "# train_label_paths = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/labels/*.tif\")\n",
        "\n",
        "\n",
        "# image_paths = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/Data_renamed/images/*.tif\")\n",
        "# label_paths = glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/Data_renamed/labels/*.tif\")\n",
        "\n",
        "image_paths = sorted(glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/Data_renamed/images/*.tif\"))\n",
        "label_paths = sorted(glob.glob(f\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/Data_renamed/labels/*.tif\"))\n",
        "\n",
        "\n",
        "# val_image_paths = glob.glob(f\"{base_dir}/validation/image/*.tif\")\n",
        "# val_label_paths = glob.glob(f\"{base_dir}/validation/label/*.tif\")"
      ],
      "metadata": {
        "id": "pI1Wn2EDWfzt"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths"
      ],
      "metadata": {
        "id": "wX7VcMnaYhWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "h4JRGj6Ooe0d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def extract_id(file_path):\n",
        "#     # This function extracts the numeric identifier from a file path, assuming the format you provided\n",
        "#     return int(os.path.basename(file_path).split('_')[0])"
      ],
      "metadata": {
        "id": "y4TmYT5_oin3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_id(file_path):\n",
        "    return os.path.basename(file_path).split('.')[0]\n",
        "\n",
        "identifiers = [extract_id(path) for path in image_paths]  # Assuming image_paths & label_paths are aligned\n",
        "\n",
        "# Split identifiers into sets for training (70%), validation (15%), and testing (15%)\n",
        "train_ids, temp_ids = train_test_split(identifiers, test_size=0.3, random_state=42)\n",
        "validation_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "_anwZjDOZF9O"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# identifiers\n",
        "# # Create a DataFrame\n",
        "# df = pd.DataFrame(identifiers)\n",
        "\n",
        "# # Print the DataFrame\n",
        "# print(df)\n",
        "\n",
        "# # Export path\n",
        "# export_path = \"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/identifiers_001.csv\"\n",
        "\n",
        "# # Export the DataFrame to a CSV file\n",
        "# df.to_csv(export_path, index=False)"
      ],
      "metadata": {
        "id": "UrO3i96VZKMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_paths(paths, ids_set):\n",
        "    return [path for path in paths if extract_id(path) in ids_set]\n",
        "\n",
        "# Split image and label paths according to the identifiers\n",
        "train_image_paths = split_paths(image_paths, set(train_ids))\n",
        "validation_image_paths = split_paths(image_paths, set(validation_ids))\n",
        "test_image_paths = split_paths(image_paths, set(test_ids))\n",
        "\n",
        "train_label_paths = split_paths(label_paths, set(train_ids))\n",
        "validation_label_paths = split_paths(label_paths, set(validation_ids))\n",
        "test_label_paths = split_paths(label_paths, set(test_ids))\n"
      ],
      "metadata": {
        "id": "pgfbYB9CZJYd"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define your image and label paths\n",
        "image_paths = glob.glob(\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/Data_renamed/images/*.tif\")\n",
        "label_paths = glob.glob(\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/Data_renamed/labels/*.tif\")\n",
        "\n",
        "# Assuming that every image has a corresponding label with the same name in their respective directories\n",
        "# Extract base names without extension to pair them\n",
        "base_names = [os.path.basename(path).split('.')[0] for path in image_paths]\n",
        "\n",
        "# Split into training, validation, and test sets (70%, 15%, 15%)\n",
        "train_names, temp_names = train_test_split(base_names, test_size=0.3, random_state=42)\n",
        "validation_names, test_names = train_test_split(temp_names, test_size=0.5, random_state=42)\n",
        "\n",
        "# Function to filter paths by identifiers\n",
        "def filter_paths(paths, ids_set):\n",
        "    return [path for path in paths if os.path.basename(path).split('.')[0] in ids_set]\n",
        "\n",
        "# Assigning paths to respective splits based on the split identifiers\n",
        "train_image_paths = filter_paths(image_paths, set(train_names))\n",
        "validation_image_paths = filter_paths(image_paths, set(validation_names))\n",
        "test_image_paths = filter_paths(image_paths, set(test_names))\n",
        "\n",
        "train_label_paths = filter_paths(label_paths, set(train_names))\n",
        "validation_label_paths = filter_paths(label_paths, set(validation_names))\n",
        "test_label_paths = filter_paths(label_paths, set(test_names))\n",
        "\n",
        "# Create a DataFrame to visualize the distribution\n",
        "data = {\n",
        "    \"Split\": [\"Training\"] * len(train_image_paths) + [\"Validation\"] * len(validation_image_paths) + [\"Test\"] * len(test_image_paths),\n",
        "    \"Image_Path\": train_image_paths + validation_image_paths + test_image_paths,\n",
        "    \"Label_Path\": train_label_paths + validation_label_paths + test_label_paths\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Show the DataFrame\n",
        "print(df)\n",
        "\n",
        "# If you want to save this table to a CSV file\n",
        "df.to_csv(\"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/split_distribution.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "bXhZTtUAZ8S-",
        "outputId": "f8a83e20-8070-4241-8d65-4f0967c049ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Split                                         Image_Path  \\\n",
            "0     Training  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "1     Training  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "2     Training  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "3     Training  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "4     Training  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "...        ...                                                ...   \n",
            "2599      Test  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "2600      Test  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "2601      Test  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "2602      Test  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "2603      Test  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "\n",
            "                                             Label_Path  \n",
            "0     /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "1     /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "2     /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "3     /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "4     /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "...                                                 ...  \n",
            "2599  /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "2600  /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "2601  /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "2602  /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "2603  /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "\n",
            "[2604 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_id(file_path):\n",
        "    # This function extracts the numeric identifier from a file path, assuming the format you provided\n",
        "    # return int(os.path.basename(file_path).split('_')[0])\n",
        "    return os.path.basename(file_path).split('.')[0]\n",
        "\n",
        "identifiers = [extract_id(path) for path in image_paths]\n",
        "\n",
        "# Split identifiers into training, validation, and test sets\n",
        "train_ids, temp_ids = train_test_split(identifiers, test_size=0.3, random_state=42)\n",
        "validation_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)\n",
        "\n",
        "# Function to split paths based on their identifiers\n",
        "def split_paths(paths, ids_set):\n",
        "    return [path for path in paths if extract_id(path) in ids_set]\n",
        "\n",
        "# Now, split all your datasets according to these ids\n",
        "train_image_paths = split_paths(image_paths, set(train_ids))\n",
        "validation_image_paths = split_paths(image_paths, set(validation_ids))\n",
        "test_image_paths = split_paths(image_paths, set(test_ids))"
      ],
      "metadata": {
        "id": "-E9G4geDS76Y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: extract_id function that extracts the information from the file to include information from before the second underscore so itll be like \"4697_5847\"\n",
        "\n",
        "# def extract_id(file_path):\n",
        "#     # This function extracts the numeric identifier from a file path, assuming the format you provided\n",
        "#     # return int(os.path.basename(file_path).split('_')[0])\n",
        "#     return os.path.basename(file_path).split('_')[0] + \"_\" + os.path.basename(file_path).split('_')[1] + \"_\" + os.path.basename(file_path).split('_')[2]\n"
      ],
      "metadata": {
        "id": "wgE0A7Q-xVuR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a unified list of identifiers from your labeled dataset, assuming nwi_ccap_path holds all possible labels\n",
        "identifiers = [extract_id(path) for path in image_paths]"
      ],
      "metadata": {
        "id": "uFOl3WayooEx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split identifiers into training, validation, and test sets\n",
        "train_ids, temp_ids = train_test_split(identifiers, test_size=0.3, random_state=42)\n",
        "validation_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "14lVNeoho0Re"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split paths based on their identifiers\n",
        "def split_paths(paths, ids_set):\n",
        "    return [path for path in paths if extract_id(path) in ids_set]"
      ],
      "metadata": {
        "id": "kV-7PO9Fo5xu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, split all your datasets according to these ids\n",
        "train_image_paths = split_paths(image_paths, set(train_ids))\n",
        "validation_image_paths = split_paths(image_paths, set(validation_ids))\n",
        "test_image_paths = split_paths(image_paths, set(test_ids))"
      ],
      "metadata": {
        "id": "t8CaM_2yo9U6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_paths"
      ],
      "metadata": {
        "id": "BC5jQGTCTfii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_image_paths"
      ],
      "metadata": {
        "id": "l6xqug4cTecb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_paths"
      ],
      "metadata": {
        "id": "Ln4YJfRFTdYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Function to list files in a folder and extract their numeric part\n",
        "def list_files(folder_path):\n",
        "    files = [f for f in os.listdir(folder_path) if f.endswith('.tif')]\n",
        "    return files\n",
        "\n",
        "# List and extract numeric parts from filenames\n",
        "# images = list_files_and_extract(images_folder)\n",
        "# labels = list_files_and_extract(labels_folder)\n",
        "\n",
        "# Find common identifiers\n",
        "# common_identifiers = set(images.keys()) & set(labels.keys())\n",
        "\n",
        "# Prepare data for DataFrame\n",
        "data = []\n",
        "for identifier in identifiers:\n",
        "    # Convert identifier to integer\n",
        "    identifier_int = int(identifier)\n",
        "    data.append({\n",
        "        'Identifier': identifier,\n",
        "        # 'Train_Image_File': train_image_paths[identifier_int],\n",
        "        'Train_Image_File': train_image_paths[identifier_int % len(train_image_paths)],\n",
        "        # 'Validation_Image_File': validation_image_paths[identifier_int],\n",
        "        'Validation_Image_File': validation_image_paths[identifier_int % len(validation_image_paths)],\n",
        "        # 'Test_Image_File': test_image_paths[identifier_int]\n",
        "        'Test_Image_File': test_image_paths[identifier_int % len(test_image_paths)]\n",
        "    })\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Sort the DataFrame by Identifier\n",
        "df.sort_values(by='Identifier', inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Add a numeric order column\n",
        "df.insert(0, 'Number', range(1, len(df) + 1))\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n",
        "\n",
        "# Export path\n",
        "export_path = \"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/train_val_test_001.csv\"\n",
        "\n",
        "# Export the DataFrame to a CSV file\n",
        "df.to_csv(export_path, index=False)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "chX48A2BUy3t",
        "outputId": "8eded0ae-6325-4e72-be49-04886a50f072",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Number     Identifier  \\\n",
            "0          1  1000_716_2331   \n",
            "1          2  1001_716_2331   \n",
            "2          3  1002_717_2331   \n",
            "3          4  1003_717_2331   \n",
            "4          5  1004_717_2331   \n",
            "...      ...            ...   \n",
            "2599    2600   997_715_2331   \n",
            "2600    2601   998_715_2331   \n",
            "2601    2602   999_715_2331   \n",
            "2602    2603    99_592_2384   \n",
            "2603    2604     9_467_2448   \n",
            "\n",
            "                                       Train_Image_File  \\\n",
            "0     /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "1     /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "2     /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "3     /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "4     /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "...                                                 ...   \n",
            "2599  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "2600  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "2601  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "2602  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "2603  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "\n",
            "                                  Validation_Image_File  \\\n",
            "0     /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "1     /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "2     /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "3     /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "4     /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "...                                                 ...   \n",
            "2599  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "2600  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "2601  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "2602  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "2603  /content/drive/MyDrive/DeepLearning_Project/tr...   \n",
            "\n",
            "                                        Test_Image_File  \n",
            "0     /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "1     /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "2     /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "3     /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "4     /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "...                                                 ...  \n",
            "2599  /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "2600  /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "2601  /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "2602  /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "2603  /content/drive/MyDrive/DeepLearning_Project/tr...  \n",
            "\n",
            "[2604 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "source": [
        "'Train_Image_File': train_image_paths[identifier_int % len(train_image_paths)],"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "yNKBtod_U8cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the folders\n",
        "# images_folder = \"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/images\"\n",
        "# labels_folder = \"/content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm5/labels\"\n",
        "\n",
        "# Function to list files in a folder and extract their numeric part\n",
        "def list_files_and_extract(folder_path):\n",
        "    files = [f for f in os.listdir(folder_path) if f.endswith('.tif')]\n",
        "    file_parts = {re.search(r\"(\\d+_\\d+)\", f).group(0): f for f in files if re.search(r\"(\\d+_\\d+)\", f)}\n",
        "    return file_parts\n",
        "\n",
        "# List and extract numeric parts from filenames\n",
        "# images = list_files_and_extract(images_folder)\n",
        "# labels = list_files_and_extract(labels_folder)\n",
        "\n",
        "# Find common identifiers\n",
        "common_identifiers = set(images.keys()) & set(labels.keys())\n",
        "\n",
        "# Prepare data for DataFrame\n",
        "data = []\n",
        "for identifier in common_identifiers:\n",
        "    data.append({\n",
        "        'Identifier': identifier,\n",
        "        'Image_File': images[identifier],\n",
        "        'Label_File': labels[identifier]\n",
        "    })\n",
        "\n"
      ],
      "metadata": {
        "id": "6XnMgk4kTyU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " set up a data loader for my structured data, considering the additional elevation channel"
      ],
      "metadata": {
        "id": "cA9Lo_NFqfAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ],
      "metadata": {
        "id": "_OaO7Ldfqh1X"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class MultiChannelDataGenerator(Sequence):\n",
        "#     def __init__(self, image_paths, elevation_paths, labels_paths, batch_size=32, dim=(128, 128), n_channels=5, n_classes=11, shuffle=True):\n",
        "#         'Initialization'\n",
        "#         self.dim = dim\n",
        "#         self.batch_size = batch_size\n",
        "#         self.image_paths = image_paths\n",
        "#         self.elevation_paths = elevation_paths\n",
        "#         self.labels_paths = labels_paths\n",
        "#         self.n_channels = n_channels\n",
        "#         self.n_classes = n_classes\n",
        "#         self.shuffle = shuffle\n",
        "#         self.on_epoch_end()\n",
        "\n",
        "#     def __len__(self):\n",
        "#         'Denotes the number of batches per epoch'\n",
        "#         return int(np.floor(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         'Generate one batch of data'\n",
        "#         # Generate indexes of the batch\n",
        "#         indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "#         # Find list of IDs\n",
        "#         list_image_temp = [self.image_paths[k] for k in indexes]\n",
        "#         list_elevation_temp = [self.elevation_paths[k] for k in indexes]\n",
        "#         list_labels_temp = [self.labels_paths[k] for k in indexes]\n",
        "\n",
        "#         # Generate data\n",
        "#         X, y = self.__data_generation(list_image_temp, list_elevation_temp, list_labels_temp)\n",
        "\n",
        "#         return X, y\n",
        "\n",
        "#     def on_epoch_end(self):\n",
        "#         'Updates indexes after each epoch'\n",
        "#         self.indexes = np.arange(len(self.image_paths))\n",
        "#         if self.shuffle == True:\n",
        "#             np.random.shuffle(self.indexes)\n",
        "\n",
        "#     def __data_generation(self, list_image_temp, list_elevation_temp, list_labels_temp):\n",
        "#         'Generates data containing batch_size samples'\n",
        "#         # Initialization\n",
        "#         X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "#         y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n",
        "\n",
        "#         # Generate data\n",
        "#         for i, (img_path, elev_path, label_path) in enumerate(zip(list_image_temp, list_elevation_temp, list_labels_temp)):\n",
        "#             # Store sample\n",
        "#             img = load_img(img_path, color_mode='rgba', target_size=self.dim)\n",
        "#             img = img_to_array(img)[:,:,:4]  # Ensure img has only 4 channels (RGBA or RGBNIR)\n",
        "\n",
        "#             elevation = load_img(elev_path, color_mode='grayscale', target_size=self.dim)\n",
        "#             elevation = img_to_array(elevation)\n",
        "#             elevation = np.repeat(elevation, 4, axis=-1)  # Repeat elevation across what would be the color channels to match dimensions\n",
        "\n",
        "#             X[i,] = np.concatenate((img, elevation), axis=-1)\n",
        "\n",
        "#             # Store class\n",
        "#             label = load_img(label_path, color_mode='grayscale', target_size=self.dim)\n",
        "#             label = img_to_array(label)\n",
        "#             y[i] = tf.keras.utils.to_categorical(label, num_classes=self.n_classes)\n",
        "\n",
        "#         return X, np.argmax(y, axis=-1)\n"
      ],
      "metadata": {
        "id": "WClXE5_HqkFm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "end"
      ],
      "metadata": {
        "id": "8PYvjX7rcrfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, image_files, label_files, img_height, img_width, batch_size, num_classes):\n",
        "        self.image_files = image_files\n",
        "        self.label_files = label_files\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        # self.noise = noise\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_files) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_batch_files = self.image_files[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "        label_batch_files = self.label_files[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "\n",
        "        batch_images, batch_labels = self.load_images_and_labels(image_batch_files,label_batch_files)\n",
        "        return batch_images, batch_labels\n",
        "\n",
        "    def load_and_reshape_image(self, image_path):\n",
        "        with rasterio.open(image_path) as src:\n",
        "            image = src.read()\n",
        "            image = image.transpose((1, 2, 0))\n",
        "            if image.shape[0] != self.img_height or image.shape[1] != self.img_width:\n",
        "                image = cv2.resize(image, (self.img_width, self.img_height), interpolation=cv2.INTER_NEAREST)\n",
        "            if len(image.shape) == 3 and image.shape[2] == 1:\n",
        "                image = np.squeeze(image, axis=2)\n",
        "\n",
        "            return image\n",
        "\n",
        "    def load_images_and_labels(self, image_files, label_files):\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for image_file in image_files:\n",
        "            image = self.load_and_reshape_image(image_file)\n",
        "            # image[image <= -3e+38] = np.nan\n",
        "\n",
        "            # # # Replace NaN values with the mean of the non-NaN pixels\n",
        "            # if np.any(np.isnan(image)):\n",
        "            #     nan_mask = np.isnan(image)\n",
        "            #     image[nan_mask] = np.nanmean(image)\n",
        "\n",
        "            # # # Replace Inf values with the mean of the non-Inf pixels\n",
        "            # if np.any(np.isinf(image)):\n",
        "            #     inf_mask = np.isinf(image)\n",
        "            #     image[inf_mask] = np.nanmean(image)\n",
        "\n",
        "            # # Convert to float\n",
        "            # image = image.astype(np.float32)\n",
        "\n",
        "            # # Z-score normalization\n",
        "            # mean = np.mean(image, axis=(0, 1), keepdims=True)\n",
        "            # std = np.std(image, axis=(0, 1), keepdims=True)\n",
        "            # # mean[mean < 0]\n",
        "            # std[std < 0] = 0\n",
        "\n",
        "            # # Normalize with epsilon to prevent divide by zero\n",
        "            # epsilon = 1e-7\n",
        "\n",
        "            # image = (image - mean) / (std + epsilon)\n",
        "\n",
        "            images.append(image)\n",
        "\n",
        "        for label_file in label_files:\n",
        "            # label_file = image_file.replace(\"planet\", \"ccap_filled\").replace('images_2018','ccap_filled')\n",
        "            label = self.load_and_reshape_image(label_file)\n",
        "            # label[label <= -3e+38] = np.nan\n",
        "\n",
        "            # # # Replace NaN values with the mean of the non-NaN pixels\n",
        "            # if np.any(np.isnan(label)):\n",
        "            #     nan_mask = np.isnan(label)\n",
        "            #     label[nan_mask] = 12\n",
        "\n",
        "            # # # Replace Inf values with the mean of the non-Inf pixels\n",
        "            # if np.any(np.isinf(label)):\n",
        "            #     inf_mask = np.isinf(label)\n",
        "            #     label[inf_mask] = 12\n",
        "\n",
        "            label -= 1\n",
        "            label = label.astype(np.int8)\n",
        "            label = to_categorical(label, num_classes=self.num_classes)\n",
        "            labels.append(label)\n",
        "\n",
        "        return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "ZGapBsD-T4zX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train_label_paths[0])\n",
        "# train_image_paths[0]"
      ],
      "metadata": {
        "id": "5-3jmoCAWx15"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm4/images_2018"
      ],
      "metadata": {
        "id": "n7VYRQYfV-m6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_gen_test = DataGenerator(sum_df['Images_path'][0:5], sum_df['Labels_path'][0:5], 512, 512, 2, 22)\n",
        "# Create the data generator\n",
        "training_data_generator = DataGenerator(train_image_paths, train_label_paths, 128, 128, 13, 12)\n",
        "# validation_data_generator = DataGenerator(sum_df['Images_path'][sum_df['random_split']==1], sum_df['Labels_path'][sum_df['random_split']==1], 512, 512, 4, 25)\n"
      ],
      "metadata": {
        "id": "yCwfJD8nViEi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/DeepLearning_Project/trainingdata/planet128x128data/utm4/ccap_filled/1004_ccap_filled.tif"
      ],
      "metadata": {
        "id": "Xr38sNZ5ZGun"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_images, batch_labels = training_data_generator.__getitem__(0)"
      ],
      "metadata": {
        "id": "oY0rx_yqX3hX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_model(img_size,num_bands, num_classes):\n",
        "#     inputs = keras.Input(shape=(img_size[0], img_size[1], num_bands))  # Change the number of channels to 4\n",
        "\n",
        "#     # Entry block\n",
        "#     x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "#     x = layers.BatchNormalization()(x)\n",
        "#     x = layers.Activation(\"LeakyReLU\")(x)\n",
        "\n",
        "#     previous_block_activation = x  # Set aside residual\n",
        "\n",
        "#     # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "#     for filters in [64, 128, 256]:\n",
        "#         x = layers.Activation(\"LeakyReLU\")(x)\n",
        "#         x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         x = layers.Activation(\"LeakyReLU\")(x)\n",
        "#         x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "#         # Project residual\n",
        "#         residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "#             previous_block_activation\n",
        "#         )\n",
        "#         x = layers.add([x, residual])  # Add back residual\n",
        "#         previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "#     for filters in [256, 128, 64, 32]:\n",
        "#         x = layers.Activation(\"LeakyReLU\")(x)\n",
        "#         x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         x = layers.Activation(\"LeakyReLU\")(x)\n",
        "#         x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "#         x = layers.BatchNormalization()(x)\n",
        "\n",
        "#         x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "#         residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "#         residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "#         x = layers.add([x, residual])  # Add back residual\n",
        "#         previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "#     # Add a per-pixel classification layer\n",
        "#     outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "#     # Define the model\n",
        "#     model = keras.Model(inputs, outputs)\n",
        "#     model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # updated to sparse categorical cross-entropy loss\n",
        "#     return model"
      ],
      "metadata": {
        "id": "9HXLq2bqarAU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "# from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
        "\n",
        "# from tensorflow.keras.layers import BatchNormalization\n",
        "# from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "# from tensorflow.python.keras.layers import BatchNormalization\n",
        "\n",
        "# U-Net model for image segmentation.\n",
        "# Encoder and decoder conncted by a center block.\n",
        "# Encoder downsamples the input image while capturing its features.\n",
        "# Decoder upsamples the encoded image to generate a segmentation map.\n",
        "\n",
        "def conv_block(input_tensor, num_filters):\n",
        "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
        "\tencoder = layers.BatchNormalization()(encoder)\n",
        "\tencoder = layers.Activation('LeakyReLU')(encoder) # from relu to LeakyReLU\n",
        "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
        "\tencoder = layers.BatchNormalization()(encoder)\n",
        "\tencoder = layers.Activation('LeakyReLU')(encoder) # from relu to LeakyReLU\n",
        "\treturn encoder\n",
        "\n",
        "def encoder_block(input_tensor, num_filters):\n",
        "\tencoder = conv_block(input_tensor, num_filters)\n",
        "\tencoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
        "\treturn encoder_pool, encoder\n",
        "\n",
        "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
        "\tdecoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
        "\tdecoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('LeakyReLU')(decoder) # from relu to LeakyReLU\n",
        "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('LeakyReLU')(decoder) # from relu to LeakyReLU\n",
        "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('LeakyReLU')(decoder) # from relu to LeakyReLU\n",
        "\treturn decoder\n",
        "\n",
        "def get_model():\n",
        "\tinputs = layers.Input(shape=[KERNEL_SIZE, KERNEL_SIZE, len(BANDS)]) # 256\n",
        "\tencoder0_pool, encoder0 = encoder_block(inputs, 32) # 128\n",
        "\tencoder1_pool, encoder1 = encoder_block(encoder0_pool, 64) # 64\n",
        "\tencoder2_pool, encoder2 = encoder_block(encoder1_pool, 128) # 32\n",
        "\tencoder3_pool, encoder3 = encoder_block(encoder2_pool, 256) # 16\n",
        "\tencoder4_pool, encoder4 = encoder_block(encoder3_pool, 512) # 8\n",
        "\tcenter = conv_block(encoder4_pool, 1024) # center\n",
        "\tdecoder4 = decoder_block(center, encoder4, 512) # 16\n",
        "\tdecoder3 = decoder_block(decoder4, encoder3, 256) # 32\n",
        "\tdecoder2 = decoder_block(decoder3, encoder2, 128) # 64\n",
        "\tdecoder1 = decoder_block(decoder2, encoder1, 64) # 128\n",
        "\tdecoder0 = decoder_block(decoder1, encoder0, 32) # 256\n",
        "\toutputs = layers.Conv2D(CLASSES, (1, 1), activation='softmax')(decoder0) # kept because this is a multiclass classification\n",
        "\n",
        "\tmodel = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "\tmodel.compile(\n",
        "\t\toptimizer=optimizers.get(OPTIMIZER),\n",
        "\t\tloss=losses.get(LOSS),\n",
        "\t\tmetrics=[metrics.get(metric) for metric in METRICS])\n",
        "\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "WOU26Rp1chre"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KERNEL_SIZE = 128\n",
        "CLASSES = 12\n",
        "BANDS = range(13)\n",
        "KERNEL_SHAPE = [128, 128]\n",
        "OPTIMIZER = 'adam'\n",
        "LOSS = 'categorical_crossentropy'\n",
        "METRICS = ['categorical_accuracy']"
      ],
      "metadata": {
        "id": "7MYIse8Lc9qy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import TenserFlow classes and functions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "NzskjnjKdRID"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = create_model([128,128],4,11)\n",
        "model = get_model()"
      ],
      "metadata": {
        "id": "8PJpkjavbr5u"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20VM6nuhg_si",
        "outputId": "0d547019-728a-4bc9-e5a5-e08bac7f3501"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 13)]       0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 128, 128, 32)         3776      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 128, 128, 32)         128       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 128, 128, 32)         0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 32)         9248      ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 128, 128, 32)         128       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 128, 128, 32)         0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 64, 64, 32)           0         ['activation_1[0][0]']        \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 64)           18496     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 64, 64, 64)           256       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 64, 64, 64)           0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 64)           36928     ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 64, 64, 64)           256       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 64, 64, 64)           0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 32, 32, 64)           0         ['activation_3[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 32, 32, 128)          512       ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 32, 32, 128)          0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 128)          147584    ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 32, 32, 128)          512       ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 32, 32, 128)          0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 16, 16, 128)          0         ['activation_5[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 16, 16, 256)          1024      ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 16, 16, 256)          0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 256)          590080    ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 16, 16, 256)          1024      ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 16, 16, 256)          0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 8, 8, 256)            0         ['activation_7[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 8, 8, 512)            1180160   ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 8, 8, 512)            2048      ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 8, 8, 512)            0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 8, 8, 512)            2359808   ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 8, 8, 512)            2048      ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 8, 8, 512)            0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 4, 4, 512)            0         ['activation_9[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 4, 4, 1024)           4719616   ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 4, 4, 1024)           4096      ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 4, 4, 1024)           0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 4, 4, 1024)           9438208   ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 4, 4, 1024)           4096      ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 4, 4, 1024)           0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 8, 8, 512)            2097664   ['activation_11[0][0]']       \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 8, 8, 1024)           0         ['activation_9[0][0]',        \n",
            "                                                                     'conv2d_transpose[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 8, 8, 1024)           4096      ['concatenate[0][0]']         \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 8, 8, 1024)           0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 8, 8, 512)            4719104   ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 8, 8, 512)            2048      ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 8, 8, 512)            0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 8, 8, 512)            2359808   ['activation_13[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 8, 8, 512)            2048      ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 8, 8, 512)            0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 16, 16, 256)          524544    ['activation_14[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 16, 16, 512)          0         ['activation_7[0][0]',        \n",
            " )                                                                   'conv2d_transpose_1[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 16, 16, 512)          2048      ['concatenate_1[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 16, 16, 512)          0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 16, 16, 256)          1179904   ['activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 16, 16, 256)          1024      ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 16, 16, 256)          0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 16, 16, 256)          590080    ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 16, 16, 256)          1024      ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 16, 16, 256)          0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2D  (None, 32, 32, 128)          131200    ['activation_17[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 32, 32, 256)          0         ['activation_5[0][0]',        \n",
            " )                                                                   'conv2d_transpose_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 32, 32, 256)          1024      ['concatenate_2[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 32, 32, 256)          0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 32, 32, 128)          295040    ['activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 32, 32, 128)          512       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 32, 32, 128)          0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 32, 32, 128)          147584    ['activation_19[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 32, 32, 128)          512       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 32, 32, 128)          0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2D  (None, 64, 64, 64)           32832     ['activation_20[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 64, 64, 128)          0         ['activation_3[0][0]',        \n",
            " )                                                                   'conv2d_transpose_3[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 64, 64, 128)          512       ['concatenate_3[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 64, 64, 128)          0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 64, 64, 64)           73792     ['activation_21[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 64, 64, 64)           256       ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_22 (Activation)  (None, 64, 64, 64)           0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 64, 64, 64)           36928     ['activation_22[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 64, 64, 64)           256       ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_23 (Activation)  (None, 64, 64, 64)           0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2D  (None, 128, 128, 32)         8224      ['activation_23[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 128, 128, 64)         0         ['activation_1[0][0]',        \n",
            " )                                                                   'conv2d_transpose_4[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 128, 128, 64)         256       ['concatenate_4[0][0]']       \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_24 (Activation)  (None, 128, 128, 64)         0         ['batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 128, 128, 32)         18464     ['activation_24[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 128, 128, 32)         128       ['conv2d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_25 (Activation)  (None, 128, 128, 32)         0         ['batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 128, 128, 32)         9248      ['activation_25[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 128, 128, 32)         128       ['conv2d_21[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_26 (Activation)  (None, 128, 128, 32)         0         ['batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 128, 128, 12)         396       ['activation_26[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31129740 (118.75 MB)\n",
            "Trainable params: 31113740 (118.69 MB)\n",
            "Non-trainable params: 16000 (62.50 KB)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy','categorical_accuracy'])\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"landcover_segmentation.h5\", save_best_only=True)\n",
        "]\n",
        "\n",
        "model.fit(training_data_generator, epochs=10, callbacks=callbacks,shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "BTy_jam1bOnZ",
        "outputId": "dd6ffca3-48d3-4e72-bd31-a4add5ff6ea1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "95/95 [==============================] - ETA: 0s - loss: nan - accuracy: 0.2241 - categorical_accuracy: 0.2241"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r95/95 [==============================] - 238s 2s/step - loss: nan - accuracy: 0.2241 - categorical_accuracy: 0.2241\n",
            "Epoch 2/10\n",
            "95/95 [==============================] - ETA: 0s - loss: nan - accuracy: 0.2241 - categorical_accuracy: 0.2241"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r95/95 [==============================] - 184s 2s/step - loss: nan - accuracy: 0.2241 - categorical_accuracy: 0.2241\n",
            "Epoch 3/10\n",
            "95/95 [==============================] - ETA: 0s - loss: nan - accuracy: 0.2241 - categorical_accuracy: 0.2241"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r95/95 [==============================] - 190s 2s/step - loss: nan - accuracy: 0.2241 - categorical_accuracy: 0.2241\n",
            "Epoch 4/10\n",
            "95/95 [==============================] - ETA: 0s - loss: nan - accuracy: 0.2241 - categorical_accuracy: 0.2241"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r95/95 [==============================] - 177s 2s/step - loss: nan - accuracy: 0.2241 - categorical_accuracy: 0.2241\n",
            "Epoch 5/10\n",
            "62/95 [==================>...........] - ETA: 1:02 - loss: nan - accuracy: 0.2074 - categorical_accuracy: 0.2074"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-acea87c52298>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}